/*
  ==============================================================================

    This file was auto-generated by the Jucer!

    It contains the basic startup code for a Juce application.

  ==============================================================================
*/

#include "PluginProcessor.h"
#include "PluginEditor.h"
#include "Zampler.h"



//==============================================================================
mlrVSTAudioProcessor::mlrVSTAudioProcessor() :
    delayBuffer (2, 12000),
    channelProcessorArray(),
    samplePool(),    // sample pool is initially empty
    numChannels(1)
{
    // Set up some default values..
    gain = 1.0f;
    delay = 0.5f;

    lastUIWidth = 400;
    lastUIHeight = 200;

    lastPosInfo.resetToDefault();
    delayPosition = 0;


    // Initialise the synth...
    //for (int i = 4; --i >= 0;)
    //{
    synth.addVoice(new ZamplerVoice());
    //}

    File testFile = File("C:\\Users\\Hemmer\\Desktop\\1 3-Audio.wav");
    WavAudioFormat wavFormat;
    ScopedPointer<AudioFormatReader> audioReader(wavFormat.createReaderFor(
                                                 new FileInputStream(testFile), true));

    BigInteger allNotes;
    allNotes.setRange(0, 128, true);

    synth.addSound(new ZamplerSound("demo sound", *audioReader, allNotes,
                                   74,   // root midi note
                                   0.05,  // attack time
                                   0.1,  // release time
                                   10.0  // maximum sample length
                                   ));

    
   // add basic sample to pool
   samplePool.addIfNotAlreadyThere(new AudioSample(testFile));

   buildChannelProcessorArray();

}

void mlrVSTAudioProcessor::buildChannelProcessorArray()
{
    AudioSample* testSample = samplePool.getUnchecked(0);

    // add the list of channels 
    for(int c = 0; c < numChannels; c++)
    {
        ChannelProcessor tempChannelProcessor(c);
        tempChannelProcessor.setCurrentSample(*testSample);
        channelProcessorArray.add(&tempChannelProcessor);
    }
}

mlrVSTAudioProcessor::~mlrVSTAudioProcessor()
{
}

//==============================================================================
int mlrVSTAudioProcessor::getNumParameters()
{
    return totalNumParams;
}

float mlrVSTAudioProcessor::getParameter (int index)
{
    // This method will be called by the host, probably on the audio thread, so
    // it's absolutely time-critical. Don't use critical sections or anything
    // UI-related, or anything at all that may block in any way!
    switch (index)
    {
        case gainParam:     return gain;
        case delayParam:    return delay;
        default:            return 0.0f;
    }
}

void mlrVSTAudioProcessor::setParameter (int index, float newValue)
{
    // This method will be called by the host, probably on the audio thread, so
    // it's absolutely time-critical. Don't use critical sections or anything
    // UI-related, or anything at all that may block in any way!
    switch (index)
    {
        case gainParam:     gain = newValue;  break;
        case delayParam:    delay = newValue;  break;
        default:            break;
    }
}

const String mlrVSTAudioProcessor::getParameterName (int index)
{
    switch (index)
    {
        case gainParam:     return "gain";
        case delayParam:    return "delay";
        default:            break;
    }

    return String::empty;
}

const String mlrVSTAudioProcessor::getParameterText (int index)
{
    return String (getParameter (index), 2);
}

//==============================================================================
void mlrVSTAudioProcessor::prepareToPlay (double sampleRate, int /*samplesPerBlock*/)
{
    // Use this method as the place to do any pre-playback
    // initialisation that you need..
    synth.setCurrentPlaybackSampleRate (sampleRate);
    keyboardState.reset();
    delayBuffer.clear();
}

void mlrVSTAudioProcessor::releaseResources()
{
    // When playback stops, you can use this as an opportunity to free up any
    // spare memory, etc.
    keyboardState.reset();
}

void mlrVSTAudioProcessor::reset()
{
    // Use this method as the place to clear any delay lines, buffers, etc, as it
    // means there's been a break in the audio's continuity.
    delayBuffer.clear();
}

void mlrVSTAudioProcessor::processBlock(AudioSampleBuffer& buffer, MidiBuffer& midiMessages)
{
    const int numSamples = buffer.getNumSamples();
    int channel, dp = 0;

    //// Go through the incoming data, and apply our gain to it...
    //for (channel = 0; channel < getNumInputChannels(); ++channel)
    //    buffer.applyGain (channel, 0, buffer.getNumSamples(), gain);

    // NOT USING
    // and now get the synth to process these midi events and generate its output.
    //synth.renderNextBlock (buffer, midiMessages, 0, numSamples);

    // for each channel, add its contributions
    // Remember to set the correct sample
    for(int c = 0; c < numChannels; c++)
    {
        ChannelProcessor *temp = channelProcessorArray[c];
        temp->renderNextBlock(buffer, midiMessages, 0, numSamples);
    }

    // Apply our delay effect to the new output..
    for (channel = 0; channel < getNumInputChannels(); ++channel)
    {
        float* channelData = buffer.getSampleData (channel);
        float* delayData = delayBuffer.getSampleData (jmin (channel, delayBuffer.getNumChannels() - 1));
        dp = delayPosition;

        for (int i = 0; i < numSamples; ++i)
        {
            const float in = channelData[i];
            channelData[i] += delayData[dp];
            delayData[dp] = (delayData[dp] + in) * delay;
            if (++dp > delayBuffer.getNumSamples())
                dp = 0;
        }
    }

    delayPosition = dp;

    // Go through the outgoing data, and apply our master gain to it...
    for (channel = 0; channel < getNumInputChannels(); ++channel)
        buffer.applyGain(channel, 0, buffer.getNumSamples(), gain);


    // In case we have more outputs than inputs, we'll clear any output
    // channels that didn't contain input data, (because these aren't
    // guaranteed to be empty - they may contain garbage).
    for (int i = getNumInputChannels(); i < getNumOutputChannels(); ++i)
        buffer.clear (i, 0, buffer.getNumSamples());



    // ask the host for the current time so we can display it...
    AudioPlayHead::CurrentPositionInfo newTime;

    if (getPlayHead() != 0 && getPlayHead()->getCurrentPosition (newTime))
    {
        // Successfully got the current time from the host..
        lastPosInfo = newTime;
    }
    else
    {
        // If the host fails to fill-in the current time, we'll just clear it to a default..
        lastPosInfo.resetToDefault();
    }
}

//==============================================================================
AudioProcessorEditor* mlrVSTAudioProcessor::createEditor()
{
    return new mlrVSTAudioProcessorEditor (this);
}

//==============================================================================
void mlrVSTAudioProcessor::getStateInformation (MemoryBlock& destData)
{
    // You should use this method to store your parameters in the memory block.
    // Here's an example of how you can use XML to make it easy and more robust:

    // Create an outer XML element..
    XmlElement xml ("MYPLUGINSETTINGS");

    // add some attributes to it..
    xml.setAttribute ("uiWidth", lastUIWidth);
    xml.setAttribute ("uiHeight", lastUIHeight);
    xml.setAttribute ("gain", gain);
    xml.setAttribute ("delay", delay);

    // then use this helper function to stuff it into the binary blob and return it..
    copyXmlToBinary (xml, destData);
}

void mlrVSTAudioProcessor::setStateInformation (const void* data, int sizeInBytes)
{
    // You should use this method to restore your parameters from this memory block,
    // whose contents will have been created by the getStateInformation() call.

    // This getXmlFromBinary() helper function retrieves our XML from the binary blob..
    ScopedPointer<XmlElement> xmlState (getXmlFromBinary (data, sizeInBytes));

    if (xmlState != 0)
    {
        // make sure that it's actually our type of XML object..
        if (xmlState->hasTagName ("MYPLUGINSETTINGS"))
        {
            // ok, now pull out our parameters..
            lastUIWidth  = xmlState->getIntAttribute ("uiWidth", lastUIWidth);
            lastUIHeight = xmlState->getIntAttribute ("uiHeight", lastUIHeight);

            gain  = (float) xmlState->getDoubleAttribute ("gain", gain);
            delay = (float) xmlState->getDoubleAttribute ("delay", delay);
        }
    }
}

const String mlrVSTAudioProcessor::getInputChannelName (const int channelIndex) const
{
    return String (channelIndex + 1);
}

const String mlrVSTAudioProcessor::getOutputChannelName (const int channelIndex) const
{
    return String (channelIndex + 1);
}

bool mlrVSTAudioProcessor::isInputChannelStereoPair (int /*index*/) const
{
    return true;
}

bool mlrVSTAudioProcessor::isOutputChannelStereoPair (int /*index*/) const
{
    return true;
}

bool mlrVSTAudioProcessor::acceptsMidi() const
{
#if JucePlugin_WantsMidiInput
    return true;
#else
    return false;
#endif
}

bool mlrVSTAudioProcessor::producesMidi() const
{
#if JucePlugin_ProducesMidiOutput
    return true;
#else
    return false;
#endif
}

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
    return new mlrVSTAudioProcessor();
}
